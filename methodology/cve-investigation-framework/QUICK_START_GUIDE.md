# CVE-2023-3446 INVESTIGATION: QUICK START GUIDE

## PHASE 1: FORENSIC EXTRACTION (Do This First)

### Step 1: Run the Forensic Extraction Script

```bash
# Navigate to tools directory
cd /Users/basiladdington/Projects/tech-debt-showcase/tools

# Make the script executable
chmod +x cve_2023_3446_forensics.sh

# Run the extraction
./cve_2023_3446_forensics.sh
```

**What This Does:**
- Extracts vulnerable code (pre-patch) from git
- Extracts patched code (post-patch) from git
- Generates unified diffs
- Creates investigation summary
- Calculates code statistics
- Maps vulnerability timeline

**Output Location:** `case-studies/CVE-2023-3446-dhtest/`

**Verification:**
```bash
# Check that extraction succeeded
ls -la ../case-studies/CVE-2023-3446-dhtest/original/
cat ../case-studies/CVE-2023-3446-dhtest/analysis/INVESTIGATION_SUMMARY.md
```

---

## PHASE 2: CREATE 6D DOCUMENTATION

### Step 2: Annotate the Vulnerable Code

**Input:** `case-studies/CVE-2023-3446-dhtest/original/dhtest.c` (extracted in Phase 1)
**Output:** `case-studies/CVE-2023-3446-dhtest/documented/dhtest-6d.c` (annotated version)

**Task:** Add 6D documentation tags to key functions in the vulnerable code.

**Target Functions to Annotate:**
Based on the CVE, focus on functions that:
1. Call or implement `DH_check()`
2. Handle DH parameter validation
3. Process untrusted input for DH keys

**Example Annotation:**
See `methodology/cve-investigation-framework/test_methodology.md` section "6D Documentation Elements to Add"

**Key Tags to Add:**
- `@intent`: What the function is supposed to do
- `@history`: How it evolved (e.g., "designed when max modulus was 2048 bits")
- `@deps`: Critical dependencies (e.g., "assumes caller validated param sizes")
- `@techdebt`: Known issues (e.g., "no upper bound check before expensive validation")
- `@arch`: Where it fits (e.g., "input validation layer in DH pipeline")
- `@security`: Threat model (e.g., "untrusted params can cause DoS")

**Annotation Strategy:**
Focus on functions that would help an AI identify:
- Input validation gaps
- Algorithmic complexity risks
- Missing bounds checks
- DoS vectors

---

## PHASE 3: RUN COMPARATIVE AI TESTS

### Step 3A: Test Control Group (Undocumented Code)

**File to Test:** `original/dhtest.c` (original sparse comments)

**Run Each Query Against GPT-4:**
See `test_methodology.md` → "Test Query Sequence" → Queries 1-3

**For Each Query:**
1. Open ChatGPT or GPT-4 API interface
2. Paste the query template
3. Replace `[PASTE: vulnerable/dhtest.c]` with actual file contents
4. Record:
   - Timestamp (start and end)
   - Full AI response
   - Whether vulnerability was detected
   - Accuracy of root cause identification
   - Quality of proposed fix

**Data Collection:**
Use the JSON template in test_methodology.md

### Step 3B: Test Experimental Group (6D-Documented Code)

**File to Test:** `documented/dhtest-6d.c` (with 6D annotations)

**Run the Same Queries:**
- Same 3 queries as control group
- Same AI model (GPT-4)
- Same recording methodology

**Compare Results:**
- Did AI detect the vulnerability more often?
- Was detection faster?
- Was root cause more accurate?
- Was proposed fix better?

### Step 3C: Repeat for Kimi K2

If you have access to Kimi K2, repeat Steps 3A and 3B.

---

## PHASE 4: SCORE AND ANALYZE

### Step 4: Score AI Responses

**Use the Scoring Rubrics:**
See `test_methodology.md` → "Scoring Rubric" sections

**Root Cause Accuracy (0-100):**
- 100%: AI identifies lack of early size validation in DH_check()
- 75%: AI identifies algorithmic complexity in DH functions
- 50%: AI mentions performance concern (not specific)
- 25%: AI mentions DH security (not the DoS vector)
- 0%: AI misses the vulnerability

**Fix Correctness (0-100):**
- 100%: Proposed fix adds parameter size check (≤32,768 bits) before validation
- 75%: Proposed fix adds size check with wrong threshold
- 50%: Proposed fix addresses performance (wrong approach)
- 25%: Proposed fix is security-related (wrong vulnerability)
- 0%: No fix or incorrect fix

**Calculate:**
- Average scores per group (control vs. experimental)
- Detection rate improvement
- Speed improvement
- Accuracy improvement

---

## PHASE 5: GENERATE FINDINGS REPORT

### Step 5: Document Results

**Create:** `case-studies/CVE-2023-3446-dhtest/findings.md`

**Include:**
1. **Executive Summary**
   - "6D documentation improved AI detection by X%"
   - "AI detection speed increased by Y seconds"
   - "Root cause accuracy improved by Z points"

2. **Quantitative Results**
   - Tables comparing control vs. experimental
   - Bar charts showing improvement
   - Statistical significance tests

3. **Qualitative Findings**
   - Example AI responses showing documentation usage
   - Evidence of AI referencing @techdebt, @security tags
   - Patterns in reasoning

4. **Conclusions**
   - Did 6D documentation help? (YES/NO + magnitude)
   - What specific tags were most useful?
   - Implications for code documentation standards
   - Insurance risk assessment impact

---

## PHASE 6: PREPARE FOR CASE STUDIES 2-5

### Step 6: Document Lessons Learned

**Create:** `research/experiments/cve-investigation-lessons.md`

**Capture:**
- What worked well in the methodology?
- What needs refinement?
- How can we streamline for CVEs 2-5?
- Which AI models performed best?
- Which 6D tags were most impactful?

**Refine for Next CVE:**
- Adjust scoring rubrics if needed
- Optimize query templates
- Improve 6D annotation guidelines
- Enhance automation scripts

---

## EXPECTED TIMELINE

- **Phase 1 (Forensics):** 15 minutes
- **Phase 2 (6D Documentation):** 2-3 hours (first time; faster for subsequent CVEs)
- **Phase 3 (Testing):** 1-2 hours (depending on AI response times)
- **Phase 4 (Scoring):** 1 hour
- **Phase 5 (Reporting):** 2-3 hours
- **Phase 6 (Lessons):** 30 minutes

**Total:** ~8-10 hours for first CVE (improves with experience)

---

## TROUBLESHOOTING

### Issue: Script fails with "fatal: not a git repository"
**Fix:** Ensure you're running the script and `REPO_PATH` points to your cloned OpenSSL repo

### Issue: Commit not found
**Fix:** Run `git fetch --all` in the OpenSSL repo to ensure you have all history

### Issue: AI doesn't detect vulnerability in control group
**Analysis:** This is valuable data! It proves the baseline detection rate is low.

### Issue: AI detects vulnerability in both groups equally
**Analysis:** Consider:
- Are the 6D annotations rich enough?
- Are you testing with queries that would benefit from the added context?
- Try more specific security-focused queries

### Issue: Results are inconsistent between runs
**Fix:** 
- Use temperature=0 for deterministic responses (if using API)
- Run multiple trials and average
- Document variance in your report

---

**GOOD LUCK WITH YOUR INVESTIGATION!**

This is groundbreaking work to quantify the value of documentation in AI-assisted security analysis.

**End of Quick Start Guide**
