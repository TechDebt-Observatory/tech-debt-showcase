# CVE-2023-3446 TEST METHODOLOGY
## Comparative AI Vulnerability Detection Study

**Hypothesis:** AI systems augmented with 6D documentation can detect vulnerabilities faster and more accurately than AI systems working with sparsely documented code.

---

## EXPERIMENTAL DESIGN

### Independent Variable
- **Documentation Level**
  - Control: Original sparse comments (9.21% coverage)
  - Experimental: 6D-augmented documentation

### Dependent Variables
1. **Detection Success** (binary: detected / not detected)
2. **Detection Time** (seconds from query to identification)
3. **Root Cause Accuracy** (0-100% match to actual CVE)
4. **Fix Correctness** (0-100% match to actual patch)
5. **False Positive Rate** (incorrect vulnerability claims)

### Test Subjects
- GPT-4 (OpenAI)
- Kimi K2 (Moonshot AI)
- (Optional: Claude Sonnet 4.5 as baseline)

---

## TEST PROTOCOL

### Phase 1: Control Group Tests (Undocumented Code)

**Dataset:** `vulnerable/dhtest.c` with original 9.21% comment coverage

**Test Query Sequence:**

#### Query 1: General Security Audit
```
I need you to perform a security audit of this C code file. Look for:
- Input validation issues
- Buffer overflows
- Integer overflows
- Algorithmic complexity attacks
- Denial of service vulnerabilities
- Logic errors that could be exploited

Analyze the code systematically and report any security concerns you find,
ranked by severity.

[PASTE: vulnerable/dhtest.c]
```

**Success Criteria:**
- AI identifies DH parameter checking issues
- AI mentions algorithmic complexity or DoS risk
- AI identifies lack of bounds checking on parameter sizes

**Metrics:**
- Time to response
- Vulnerability mentioned: YES/NO
- Severity assessment: CORRECT/INCORRECT
- Root cause identified: YES/NO/PARTIAL

---

#### Query 2: Targeted DH Analysis
```
This file contains Diffie-Hellman key testing functions. Please analyze
the DH_check(), DH_check_ex(), and related functions for:

1. Parameter validation
2. Handling of oversized parameters
3. Computational complexity concerns
4. Potential denial of service vectors

What vulnerabilities do you see?

[PASTE: vulnerable/dhtest.c]
```

**Success Criteria:**
- AI identifies excessive computation on large parameters
- AI mentions lack of early termination
- AI proposes adding parameter size limits

**Metrics:**
- Specific function identified: YES/NO
- DoS vector explained: YES/NO/PARTIAL
- Proposed fix aligns with actual patch: YES/NO/PARTIAL

---

#### Query 3: Direct CVE Reproduction Test
```
Imagine you are a security researcher testing this OpenSSL test file.
An attacker can supply excessively large DH parameters. Walk through
what happens when:

1. A DH modulus larger than 10,000 bits is provided
2. DH_check() is called on these parameters
3. The function continues checking even after detecting oversized parameters

What is the security impact?

[PASTE: vulnerable/dhtest.c]
```

**Success Criteria:**
- AI traces the execution path
- AI identifies the performance issue
- AI assigns DoS classification
- AI proposes the correct fix (early termination, size limit)

**Metrics:**
- Execution path traced: YES/NO
- DoS impact identified: YES/NO
- Proposed fix matches CVE-2023-3446 patch: SCORE 0-100%

---

### Phase 2: Experimental Group Tests (6D-Documented Code)

**Dataset:** `vulnerable/dhtest.c` augmented with 6D documentation

**6D Documentation Elements to Add:**

```c
/**
 * @intent: Validate Diffie-Hellman parameters for cryptographic safety.
 *          Ensures DH modulus is prime, generator is valid, and parameters
 *          meet minimum security requirements for key exchange.
 *
 * @history: Originally designed for basic DH validation. Over time, checks
 *           expanded to include complex primality testing and subgroup
 *           verification. Performance assumptions made when max modulus
 *           was implicitly limited to ~2048 bits.
 *
 * @deps: Depends on:
 *        - BN_num_bits() for parameter size checking
 *        - BN_is_prime_ex() for primality verification (computationally expensive)
 *        - Assumes caller has already validated parameter sizes
 *        ⚠️  CRITICAL: Does not enforce maximum parameter sizes
 *
 * @techdebt: Known issues:
 *            - No explicit upper bound on modulus size before validation
 *            - Expensive primality checks run even on obviously invalid params
 *            - Could DOS if attacker provides multi-kilobit parameters
 *            - TODO: Add early size validation before expensive checks
 *
 * @arch: Part of DH key validation pipeline:
 *        EVP_PKEY_param_check() -> DH_check_ex() -> DH_check()
 *        Used by command-line tools (dhparam, pkeyparam) and API consumers
 *        Position: Input validation layer (should fail fast)
 *
 * @security: INPUT VALIDATION CONCERN:
 *            - Untrusted parameter source can cause excessive computation
 *            - Lack of size pre-check enables algorithmic complexity attack
 *            - Defense: Should validate size BEFORE expensive operations
 *            - Risk: Denial of Service via resource exhaustion
 */
static int dh_check_test(int idx) {
    // ... existing code ...
}
```

**Test Query Sequence:** (Same as Phase 1)

Run identical queries but with 6D-documented version.

---

### Phase 3: Data Collection

**For Each AI × Documentation Level × Query Combination:**

| Metric | Measurement Method |
|--------|-------------------|
| Detection Success | Binary: Did AI mention the vulnerability? |
| Detection Time | Timestamp from query to first mention of issue |
| Root Cause Accuracy | Human scoring 0-100% match to CVE description |
| Fix Correctness | Code diff similarity to actual patch |
| False Positives | Count of incorrectly identified vulnerabilities |
| Confidence Level | AI's stated confidence (if provided) |

**Scoring Rubric for Root Cause Accuracy:**

- **100%**: AI identifies excessive computation in DH_check() due to lack of early size validation
- **75%**: AI identifies algorithmic complexity issue in DH functions
- **50%**: AI mentions performance concern but not specific to parameter validation
- **25%**: AI mentions DH security but not the specific DoS vector
- **0%**: AI does not identify any relevant vulnerability

**Scoring Rubric for Fix Correctness:**

- **100%**: Proposed fix adds early parameter size check (≤32,768 bits) before expensive validation
- **75%**: Proposed fix adds size check but with incorrect threshold
- **50%**: Proposed fix addresses performance but not via size validation
- **25%**: Proposed fix is security-related but doesn't address root cause
- **0%**: No fix proposed or proposed fix is incorrect

---

## DATA COLLECTION TEMPLATE

### Test Run Record

```json
{
  "test_id": "CVE-2023-3446-001",
  "ai_model": "GPT-4",
  "documentation_level": "control",  // or "experimental"
  "query_number": 1,
  "timestamp": "2025-11-18T10:30:00Z",
  "results": {
    "detection_success": true,
    "detection_time_seconds": 8.5,
    "vulnerability_mentioned": true,
    "root_cause_accuracy_score": 75,
    "fix_correctness_score": 50,
    "false_positives": 1,
    "ai_confidence": "medium",
    "specific_findings": [
      "AI mentioned DH parameter validation",
      "AI identified computational complexity",
      "AI proposed adding timeout (incorrect fix)"
    ],
    "ai_response_excerpt": "...",
    "notes": "AI detected issue but proposed timeout instead of size check"
  }
}
```

---

## ANALYSIS PLAN

### Statistical Tests
1. **Detection Rate Comparison**
   - Chi-square test: Detection success (control vs. experimental)
   - Expected: Higher detection rate with 6D documentation

2. **Speed Comparison**
   - Mann-Whitney U test: Detection time (control vs. experimental)
   - Expected: Faster detection with 6D documentation

3. **Accuracy Comparison**
   - Independent samples t-test: Root cause scores (control vs. experimental)
   - Independent samples t-test: Fix correctness scores (control vs. experimental)
   - Expected: Higher scores with 6D documentation

### Effect Size Calculation
- Cohen's d for continuous metrics
- Odds ratio for binary outcomes

### Significance Level
- α = 0.05

---

## EXPECTED OUTCOMES

### H1: Detection Rate
**Null:** No difference in detection rates between control and experimental groups.
**Alternative:** 6D documentation increases detection rate.
**Predicted:** 40-60% detection in control, 80-95% detection in experimental.

### H2: Detection Speed
**Null:** No difference in detection speed.
**Alternative:** 6D documentation reduces time to detection.
**Predicted:** 30-50% faster detection with 6D documentation.

### H3: Root Cause Accuracy
**Null:** No difference in accuracy scores.
**Alternative:** 6D documentation improves accuracy.
**Predicted:** 20-30 point increase in average accuracy score.

### H4: Fix Correctness
**Null:** No difference in fix quality.
**Alternative:** 6D documentation improves fix proposals.
**Predicted:** 25-40 point increase in average fix score.

---

## QUALITATIVE ANALYSIS

### Thematic Coding of AI Responses

**Code Categories:**
1. **Correct Identification**
   - Mentions algorithmic complexity
   - Identifies lack of bounds checking
   - Traces execution path to DoS

2. **Partial Identification**
   - General performance concerns
   - Security concerns without specifics
   - Related but not exact vulnerability

3. **Misidentification**
   - Unrelated security issues
   - Incorrect root cause
   - Overstated severity

4. **Documentation Usage**
   - References @techdebt tags
   - Cites @security warnings
   - Uses @deps for context

### AI Response Patterns

Track whether AI models:
- Reference specific documentation tags
- Show reasoning influenced by historical context (@history)
- Propose fixes aligned with architectural constraints (@arch)
- Demonstrate awareness of known technical debt (@techdebt)

---

## REPORTING FORMAT

### Final Report Structure

1. **Executive Summary**
   - Key findings
   - Statistical significance
   - Effect sizes
   - Practical implications

2. **Methodology**
   - Experimental design
   - AI models tested
   - Documentation framework
   - Scoring rubrics

3. **Quantitative Results**
   - Detection rates (with confidence intervals)
   - Speed metrics
   - Accuracy scores
   - Statistical test results

4. **Qualitative Findings**
   - AI reasoning patterns
   - Documentation usage evidence
   - Unexpected behaviors

5. **Discussion**
   - Interpretation of results
   - Limitations
   - Implications for code documentation
   - Insurance risk assessment

6. **Conclusions**
   - Did 6D documentation improve AI detection?
   - By how much?
   - Cost-benefit analysis
   - Recommendations for practice

---

## AUTOMATION SCRIPT TEMPLATE

```python
#!/usr/bin/env python3
"""
CVE-2023-3446 Automated Test Runner
Runs comparative AI vulnerability detection tests
"""

import json
import time
from datetime import datetime
from openai import OpenAI
# from kimi import KimiAPI  # Example for Kimi K2

class CVETestRunner:
    def __init__(self, ai_client, code_file, query_set):
        self.client = ai_client
        self.code = self.load_code(code_file)
        self.queries = query_set
        
    def load_code(self, filepath):
        with open(filepath, 'r') as f:
            return f.read()
    
    def run_test(self, query_template):
        """Execute a single test query"""
        query = query_template.replace('[PASTE: vulnerable/dhtest.c]', self.code)
        
        start_time = time.time()
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": query}]
        )
        end_time = time.time()
        
        return {
            "response": response.choices[0].message.content,
            "time_seconds": end_time - start_time,
            "timestamp": datetime.now().isoformat()
        }
    
    def score_response(self, response_text):
        """Score AI response for accuracy"""
        # Implement scoring logic based on rubrics
        scores = {
            "detection_success": False,
            "root_cause_accuracy": 0,
            "fix_correctness": 0,
            "false_positives": 0
        }
        
        # Check for key vulnerability indicators
        if "algorithmic complexity" in response_text.lower():
            scores["detection_success"] = True
            scores["root_cause_accuracy"] += 25
        
        if "dh_check" in response_text.lower():
            scores["root_cause_accuracy"] += 25
            
        if "parameter size" in response_text.lower():
            scores["root_cause_accuracy"] += 25
            
        if "denial of service" in response_text.lower():
            scores["root_cause_accuracy"] += 25
        
        # Add fix correctness scoring logic here
        
        return scores

# Usage:
# runner_control = CVETestRunner(openai_client, "vulnerable/dhtest.c", QUERY_SET)
# runner_experimental = CVETestRunner(openai_client, "vulnerable/dhtest_6d.c", QUERY_SET)
# results = runner_control.run_all_tests()
```

---

## VALIDATION CHECKLIST

Before running experiments:
- [ ] Vulnerable code extracted and verified
- [ ] 6D documentation created for experimental group
- [ ] All three queries finalized
- [ ] AI API access confirmed (GPT-4, Kimi K2)
- [ ] Scoring rubrics validated with sample responses
- [ ] Data collection template tested
- [ ] Statistical analysis plan reviewed
- [ ] IRB/ethics approval (if publishing academically)

---

**Next Step:** Generate 6D documentation for vulnerable code.

---

## APPENDIX: Example 6D Documentation Template

See section "6D Documentation Elements to Add" above for full example.

Key principles:
1. **@intent**: What should this code do? (Design specification)
2. **@history**: How did we get here? (Evolution and assumptions)
3. **@deps**: What does this depend on? (Critical dependencies)
4. **@techdebt**: What's known to be problematic? (Acknowledged issues)
5. **@arch**: How does this fit? (System context)
6. **@security**: What are the risks? (Threat model)

Each dimension should directly address information gaps that would help
AI systems reason about security properties.

**End of Test Methodology**
