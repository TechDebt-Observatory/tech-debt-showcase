# CVE-2023-3446 INVESTIGATION FRAMEWORK
## Complete NTSB-Style Crash Investigation for 6D Documentation Validation

**Version:** 1.0  
**Date:** November 18, 2025  
**Investigator:** Baz  
**Purpose:** Prove that AI + comprehensive documentation catches vulnerabilities faster than AI + sparse documentation

---

## üìã EXECUTIVE SUMMARY

This framework provides a complete, reproducible methodology for investigating CVE-2023-3446 (OpenSSL DH_check() DoS vulnerability) to validate the effectiveness of 6-dimensional documentation in AI-assisted security analysis.

**CVE-2023-3446 Quick Facts:**
- **Type:** Denial of Service (algorithmic complexity)
- **Severity:** LOW (CVSS 3.7)
- **Discovered:** June 25, 2023 (OSSfuzz)
- **Disclosed:** July 19, 2023
- **Root Cause:** DH_check() continues expensive validation even after detecting oversized parameters
- **Fix:** Added 32,768-bit maximum limit for DH parameter checks

**Research Question:**  
Does 6D documentation improve AI's ability to detect vulnerabilities in legacy code?

**Expected Outcome:**  
AI systems with 6D-documented code will show:
- Higher detection rates (40-60% ‚Üí 80-95%)
- Faster detection times (30-50% improvement)
- Better root cause accuracy (+20-30 points)
- More correct proposed fixes (+25-40 points)

---

## üéØ WHAT IS 6D DOCUMENTATION?

A documentation framework that captures six critical dimensions of code understanding:

1. **@intent** - What the code is supposed to do (design spec)
2. **@history** - How it evolved (assumptions, design decisions)
3. **@deps** - Critical dependencies and assumptions
4. **@techdebt** - Known issues and acknowledged problems
5. **@arch** - System context and relationships
6. **@security** - Threat model and risk assessment

**Hypothesis:** These dimensions provide context that helps AI systems reason about security properties that would be invisible in sparse inline comments.

---

## üìÅ FILES IN THIS FRAMEWORK

### Core Scripts
1. **`cve_2023_3446_forensics.sh`** - Automated git archaeology script
   - Extracts vulnerable and patched code
   - Generates diffs and timelines
   - Creates investigation summary
   - **Run this first!**

### Documentation
2. **`QUICK_START_GUIDE.md`** - Step-by-step execution guide
   - Phase-by-phase instructions
   - Troubleshooting tips
   - Timeline estimates
   - Checklist

3. **`test_methodology.md`** - Complete research methodology
   - Experimental design
   - Test queries (3 standardized queries)
   - Scoring rubrics
   - Statistical analysis plan
   - Expected outcomes

4. **`data_collection_template.md`** - Structured recording format
   - Individual test record templates
   - Comparison tables
   - Statistical analysis sections
   - Qualitative observation fields

5. **`README.md`** - This file (master overview)

---

## üöÄ QUICK START (5 Steps)

### Step 1: Extract Forensic Evidence
```bash
cd /Users/basiladdington/Projects/tech-debt-showcase/tools
chmod +x cve_2023_3446_forensics.sh
./cve_2023_3446_forensics.sh
```
**Output:** Case study directories will be populated

### Step 2: Create 6D Documentation
Annotate `original/dhtest.c` with 6D tags.  
See `test_methodology.md` for examples.

### Step 3: Run Control Tests
Test GPT-4 and Kimi K2 against undocumented code (3 queries each).

### Step 4: Run Experimental Tests
Test same AI models against 6D-documented code (3 queries each).

### Step 5: Analyze Results
Score responses using rubrics, calculate improvements, generate report.

**See `QUICK_START_GUIDE.md` for detailed instructions.**

---

## üìä EXPERIMENTAL DESIGN

### Variables
- **Independent Variable:** Documentation level (control vs. experimental)
- **Dependent Variables:**
  - Detection success (binary)
  - Detection time (seconds)
  - Root cause accuracy (0-100 scale)
  - Fix correctness (0-100 scale)
  - False positive rate

### Sample Size
- **Minimum:** 12 tests (2 AI models √ó 2 conditions √ó 3 queries)
- **Recommended:** 24+ tests (multiple trials for statistical power)

### AI Models
- Primary: GPT-4 (OpenAI)
- Secondary: Kimi K2 (Moonshot AI)
- Optional: Claude Sonnet 4.5 (Anthropic)

### Test Queries
1. **General Security Audit** - Open-ended vulnerability scan
2. **Targeted DH Analysis** - Focused on Diffie-Hellman functions
3. **Direct CVE Reproduction** - Traces the specific attack vector

**Full query text in `test_methodology.md`**

---

## üìè SCORING RUBRICS

### Root Cause Accuracy (0-100)
- **100:** Identifies lack of early size validation in DH_check()
- **75:** Identifies algorithmic complexity in DH functions
- **50:** Mentions performance concern (not specific)
- **25:** Mentions DH security (not the DoS vector)
- **0:** Misses the vulnerability

### Fix Correctness (0-100)
- **100:** Proposes parameter size check (‚â§32,768 bits) before validation
- **75:** Proposes size check with wrong threshold
- **50:** Addresses performance (wrong approach)
- **25:** Security-related (wrong vulnerability)
- **0:** No fix or incorrect fix

**Use `data_collection_template.md` to record scores.**

---

## üî¨ METHODOLOGY HIGHLIGHTS

### Strengths
- **Reproducible:** Standardized queries and scoring
- **Quantitative:** Multiple measurable outcomes
- **Controlled:** Same code, same CVE, different documentation
- **Practical:** Real vulnerability, real code, real AI systems

### Limitations
- Small sample size (1 CVE, 1 file)
- Specific to DoS vulnerabilities
- Limited to text-based AI models
- Scoring involves human judgment

### Mitigations
- Plan includes 4 additional CVE case studies (total: 5)
- Scoring rubrics are explicit and documented
- Multiple AI models reduce model-specific bias
- Statistical tests quantify significance

---

## üìà EXPECTED RESULTS

### Detection Rate
- **Control (undocumented):** 40-60% detection
- **Experimental (6D documented):** 80-95% detection
- **Improvement:** +40-55 percentage points

### Detection Speed
- **Control:** Baseline (e.g., 15 seconds average)
- **Experimental:** 30-50% faster
- **Improvement:** 5-8 seconds saved

### Root Cause Accuracy
- **Control:** 30-50/100 average
- **Experimental:** 60-80/100 average
- **Improvement:** +20-30 points

### Fix Correctness
- **Control:** 25-40/100 average
- **Experimental:** 50-70/100 average
- **Improvement:** +25-40 points

**If results confirm hypothesis, this provides evidence that undocumented code = uninsurable risk.**

---

## üìÇ OUTPUT STRUCTURE

### After Running Forensics Script
```
case-studies/CVE-2023-3446-dhtest/
‚îú‚îÄ‚îÄ original/
‚îÇ   ‚îú‚îÄ‚îÄ dhtest.c              # Pre-patch code (954 lines, 9.21% comments)
‚îÇ   ‚îî‚îÄ‚îÄ metadata.txt          # Commit details, statistics
‚îú‚îÄ‚îÄ documented/
‚îÇ   ‚îî‚îÄ‚îÄ dhtest-6d.c           # With 6D annotations (you create this)
‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îú‚îÄ‚îÄ INVESTIGATION_SUMMARY.md  # Complete crash report
‚îÇ   ‚îú‚îÄ‚îÄ diffs/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unified.diff          # Git diff showing changes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ word-diff.txt         # Word-level diff
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stats.txt             # Change statistics
‚îÇ   ‚îî‚îÄ‚îÄ metadata/
‚îÇ       ‚îú‚îÄ‚îÄ patch_commit_details.txt
‚îÇ       ‚îú‚îÄ‚îÄ timeline.txt          # Discovery ‚Üí disclosure ‚Üí patch timeline
‚îÇ       ‚îî‚îÄ‚îÄ vulnerability_locations.txt
‚îî‚îÄ‚îÄ ai-detection-results/
    ‚îú‚îÄ‚îÄ control-group/
    ‚îÇ   ‚îú‚îÄ‚îÄ gpt4-query1.md
    ‚îÇ   ‚îú‚îÄ‚îÄ gpt4-query2.md
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ experimental-group/
        ‚îú‚îÄ‚îÄ gpt4-query1.md
        ‚îî‚îÄ‚îÄ ...
```

---

## üéì BEST PRACTICES

### When Creating 6D Documentation
1. **Be Specific:** Don't just say "validates parameters" - explain what validation, what happens if it fails
2. **Include History:** Explain when/why the code was written this way
3. **Call Out Risks:** Explicitly mention security concerns in @security tags
4. **Link Dependencies:** Explain what assumptions this code makes about callers
5. **Document Tech Debt:** If you know there's a problem, say so in @techdebt

### When Testing AI Models
1. **Use Identical Prompts:** Don't rephrase between control and experimental
2. **Record Everything:** Full responses, timestamps, model versions
3. **Test Multiple Times:** AI responses can vary - average multiple runs
4. **Control for Order Effects:** Randomize which condition you test first
5. **Blind Scoring:** Score responses without knowing which group they're from

### When Analyzing Results
1. **Report Null Results:** If documentation doesn't help, that's valuable data
2. **Examine Failures:** Why did AI miss the vulnerability?
3. **Note Unexpected Findings:** Did AI catch something else?
4. **Consider Context:** Is this CVE representative of typical vulnerabilities?

---

## üîß TROUBLESHOOTING

### "fatal: not a git repository"
‚Üí Ensure `REPO_PATH` in the script points to your cloned OpenSSL repo

### "fatal: bad object" or "commit not found"
‚Üí Run `git fetch --all` in OpenSSL repo to get complete history

### AI doesn't detect vulnerability
‚Üí **This is expected for control group!** It's part of proving the baseline is low.

### Scoring is difficult
‚Üí Use the rubrics in `test_methodology.md` and document your reasoning

### AI responses vary between runs
‚Üí Use temperature=0 for deterministic responses, or run multiple trials and average

---

## üìñ READING ORDER

**New to this framework?**
1. Start with this README (you're here!)
2. Read `QUICK_START_GUIDE.md` for step-by-step instructions
3. Review `test_methodology.md` for the full methodology
4. Use `data_collection_template.md` while recording results

**Ready to execute?**
1. Run `cve_2023_3446_forensics.sh` from the tools/ directory
2. Create 6D documentation (see methodology doc for examples)
3. Follow phases in `QUICK_START_GUIDE.md`
4. Record data in `data_collection_template.md`

**Analyzing results?**
1. Review scoring rubrics in methodology doc
2. Fill in comparison tables in data template
3. Calculate statistical tests (chi-square, t-tests)
4. Write findings report

---

## üîç RELATED RESOURCES

### OpenSSL References
- **CVE Details:** https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-3446
- **Security Advisory:** https://www.openssl.org/news/secadv/20230719.txt
- **Patch Commit:** https://github.com/openssl/openssl/commit/9e0094e2aa1b3428a12d5095132f133c078d3c3d

### Academic Context
- **OSSfuzz Project:** Google's automated fuzzing for open source
- **CVSS Scoring:** https://www.first.org/cvss/
- **NTSB Methodology:** National Transportation Safety Board investigation framework

### AI Models
- **GPT-4:** https://platform.openai.com/docs/models/gpt-4
- **Kimi K2:** Moonshot AI (China-based LLM)
- **Claude:** https://www.anthropic.com/claude

---

## üéØ SUCCESS CRITERIA

This investigation is successful if:
1. ‚úÖ Vulnerable and patched code extracted via forensics script
2. ‚úÖ 6D documentation created for experimental group
3. ‚úÖ All 12 tests completed (2 models √ó 2 conditions √ó 3 queries)
4. ‚úÖ Results scored using standardized rubrics
5. ‚úÖ Findings report generated with quantitative comparisons
6. ‚úÖ Statistical significance determined (p-values calculated)
7. ‚úÖ Lessons learned documented for CVEs 2-5

**Primary Goal:** Quantify whether 6D documentation improves AI vulnerability detection.

**Secondary Goal:** Identify which 6D tags are most valuable for security analysis.

---

## üìä METRICS TO TRACK

### Quantitative
- [ ] Detection rate (control vs. experimental)
- [ ] Average detection time
- [ ] Root cause accuracy scores
- [ ] Fix correctness scores
- [ ] False positive counts
- [ ] Statistical significance (p-values)
- [ ] Effect sizes (Cohen's d)

### Qualitative
- [ ] Which 6D tags did AI reference?
- [ ] How did AI reasoning change with documentation?
- [ ] What unexpected vulnerabilities did AI find?
- [ ] What patterns emerged in successful detections?

---

## üö¶ NEXT STEPS

### Immediate (Today)
1. Run `cve_2023_3446_forensics.sh`
2. Review extracted files
3. Read CVE details in `analysis/INVESTIGATION_SUMMARY.md`

### Short-term (This Week)
4. Create 6D documentation for vulnerable code
5. Run 12 core tests (2 models √ó 2 conditions √ó 3 queries)
6. Record results in data template

### Medium-term (Next 2 Weeks)
7. Score all responses using rubrics
8. Calculate statistics
9. Write findings report
10. Document lessons learned

### Long-term (Next Month)
11. Select CVEs 2-5 for remaining case studies
12. Refine methodology based on lessons learned
13. Build comprehensive evidence portfolio
14. Prepare presentation for insurance/security stakeholders

---

## üí° WHY THIS MATTERS

### For Open Source Maintainers
- Quantifies the value of documentation
- Provides evidence for documentation standards
- Identifies which documentation helps AI the most

### For Security Researchers
- Tests AI's ability to find real vulnerabilities
- Compares AI performance across documentation levels
- Informs best practices for AI-assisted security audits

### For Insurance / Risk Assessment
- Provides empirical evidence that undocumented code = higher risk
- Quantifies the security value of comprehensive documentation
- Builds case that poorly documented code may be uninsurable

### For AI Safety
- Tests AI's reasoning with and without context
- Identifies failure modes in AI security analysis
- Improves understanding of how to augment AI with documentation

---

## üìù CITATION

If you use or adapt this framework:

```
Baz. (2025). CVE-2023-3446 NTSB-Style Investigation Framework: 
Validating 6-Dimensional Documentation for AI-Assisted Security Analysis. 
Case Study 1 of 5. Legacy Code Documentation Project.
```

---

## ü§ù CONTRIBUTING

This is case study 1 of 5. Lessons learned will refine:
- Documentation annotation guidelines
- Query templates
- Scoring rubrics
- Statistical methods
- Automation scripts

Feedback and improvements welcome after completing this investigation.

---

## ‚öñÔ∏è LICENSE & ETHICS

**Data Usage:**
- OpenSSL code is licensed under Apache 2.0
- CVE information is public domain
- AI responses are subject to terms of service of respective providers

**Ethical Considerations:**
- This is retrospective analysis of a patched vulnerability
- No active exploitation or weaponization
- Results will be shared to improve code security practices

---

## üìß SUPPORT

For questions about this framework:
1. Review the methodology document
2. Check the Quick Start Guide
3. Consult the troubleshooting section
4. Review related CVE documentation

---

## ‚úÖ FINAL CHECKLIST

Before beginning:
- [ ] OpenSSL repo cloned (location will be configured in forensics script)
- [ ] Git history is complete (not shallow clone)
- [ ] Output directory is writable
- [ ] GPT-4 API access confirmed
- [ ] Kimi K2 access confirmed (if using)
- [ ] Familiar with 6D documentation framework
- [ ] Reviewed scoring rubrics
- [ ] Data collection template ready

You are ready to begin! üöÄ

---

**Document Version:** 1.0  
**Last Updated:** November 18, 2025  
**Status:** Ready for execution  

**End of README**
